CTCLoss	crnn_main.py	/^from warpctc_pytorch import CTCLoss$/;"	i
Variable	crnn_main.py	/^from torch.autograd import Variable$/;"	i
argparse	crnn_main.py	/^import argparse$/;"	i
backends	crnn_main.py	/^import torch.backends.cudnn as cudnn$/;"	i
betas	crnn_main.py	/^                               betas=(params.beta1, 0.999))$/;"	v
collate_fn	crnn_main.py	/^        collate_fn=dataset.alignCollate(imgH=params.imgH, imgW=params.imgW, keep_ratio=params.keep_ratio))$/;"	v
converter	crnn_main.py	/^    converter = utils.strLabelConverter(params.alphabet)$/;"	v
criterion	crnn_main.py	/^        criterion = criterion.cuda()$/;"	v
criterion	crnn_main.py	/^    criterion = CTCLoss()$/;"	v
crnn	crnn_main.py	/^    crnn = crnn.CRNN(params.imgH, nc, nclass, params.nh)$/;"	v
crnn	crnn_main.py	/^import models.crnn as crnn$/;"	i
cudnn	crnn_main.py	/^import torch.backends.cudnn as cudnn$/;"	i
data	crnn_main.py	/^import torch.utils.data$/;"	i
dataset	crnn_main.py	/^import dataset$/;"	i
image	crnn_main.py	/^        image = image.cuda()$/;"	v
image	crnn_main.py	/^    image = Variable(image)$/;"	v
image	crnn_main.py	/^    image = torch.FloatTensor(params.batchSize, 3, params.imgH, params.imgH)$/;"	v
length	crnn_main.py	/^    length = Variable(length)$/;"	v
length	crnn_main.py	/^    length = torch.IntTensor(params.batchSize)$/;"	v
loss_avg	crnn_main.py	/^    loss_avg = utils.averager()$/;"	v
manualSeed	crnn_main.py	/^    manualSeed = random.randint(1, 10000)  # fix seed$/;"	v
models	crnn_main.py	/^import models.crnn as crnn$/;"	i
nc	crnn_main.py	/^    nc = 1$/;"	v
nclass	crnn_main.py	/^    nclass = len(params.alphabet) + 1$/;"	v
np	crnn_main.py	/^import numpy as np$/;"	i
num_workers	crnn_main.py	/^        num_workers=int(params.workers),$/;"	v
opt	crnn_main.py	/^opt = parser.parse_args()$/;"	v
optim	crnn_main.py	/^import torch.optim as optim$/;"	i
optimizer	crnn_main.py	/^        optimizer = optim.Adadelta(crnn.parameters(), lr=params.lr)$/;"	v
optimizer	crnn_main.py	/^        optimizer = optim.Adam(crnn.parameters(), lr=params.lr,$/;"	v
optimizer	crnn_main.py	/^        optimizer = optim.RMSprop(crnn.parameters(), lr=params.lr)$/;"	v
os	crnn_main.py	/^import os$/;"	i
params	crnn_main.py	/^import params$/;"	i
parser	crnn_main.py	/^parser = argparse.ArgumentParser()$/;"	v
print_function	crnn_main.py	/^from __future__ import print_function$/;"	i
random	crnn_main.py	/^import random$/;"	i
re	crnn_main.py	/^import re$/;"	i
sampler	crnn_main.py	/^        sampler = None$/;"	v
sampler	crnn_main.py	/^        sampler = dataset.randomSequentialSampler(train_dataset, params.batchSize)$/;"	v
test_dataset	crnn_main.py	/^    test_dataset = dataset.lmdbDataset($/;"	v
text	crnn_main.py	/^    text = Variable(text)$/;"	v
text	crnn_main.py	/^    text = torch.IntTensor(params.batchSize * 5)$/;"	v
torch	crnn_main.py	/^import torch$/;"	i
torch	crnn_main.py	/^import torch.backends.cudnn as cudnn$/;"	i
torch	crnn_main.py	/^import torch.optim as optim$/;"	i
torch	crnn_main.py	/^import torch.utils.data$/;"	i
trainBatch	crnn_main.py	/^def trainBatch(net, criterion, optimizer, train_iter):$/;"	f
train_dataset	crnn_main.py	/^    train_dataset = dataset.lmdbDataset(root=opt.trainroot)$/;"	v
train_loader	crnn_main.py	/^    train_loader = torch.utils.data.DataLoader($/;"	v
training	crnn_main.py	/^def training():$/;"	f
utils	crnn_main.py	/^import torch.utils.data$/;"	i
utils	crnn_main.py	/^import utils$/;"	i
val	crnn_main.py	/^def val(net, dataset, criterion, max_iter=100):$/;"	f
weights_init	crnn_main.py	/^def weights_init(m):$/;"	f
Image	data_generator\generator.py	/^from PIL import Image, ImageDraw, ImageFont, ImageFilter$/;"	i
ImageDraw	data_generator\generator.py	/^from PIL import Image, ImageDraw, ImageFont, ImageFilter$/;"	i
ImageFilter	data_generator\generator.py	/^from PIL import Image, ImageDraw, ImageFont, ImageFilter$/;"	i
ImageFont	data_generator\generator.py	/^from PIL import Image, ImageDraw, ImageFont, ImageFilter$/;"	i
create_an_image	data_generator\generator.py	/^def create_an_image(bground_path, width, height):$/;"	f
cv2	data_generator\generator.py	/^import cv2$/;"	i
darken_func	data_generator\generator.py	/^def darken_func(image):$/;"	f
file	data_generator\generator.py	/^    file  = open('data_set\/val_set.txt', 'w', encoding='utf-8')$/;"	v
glob	data_generator\generator.py	/^import glob$/;"	i
info_list	data_generator\generator.py	/^        info_list = [part.strip().replace('\\t', '') for part in file.readlines()]$/;"	v
info_str	data_generator\generator.py	/^        info_str = ''.join(info_list)$/;"	v
main	data_generator\generator.py	/^def main(save_path, num, file):$/;"	f
np	data_generator\generator.py	/^import numpy as np$/;"	i
os	data_generator\generator.py	/^import os$/;"	i
random	data_generator\generator.py	/^import random$/;"	i
random_choice_in_process_func	data_generator\generator.py	/^def random_choice_in_process_func():$/;"	f
random_font	data_generator\generator.py	/^def random_font(font_path):$/;"	f
random_font_size	data_generator\generator.py	/^def random_font_size():$/;"	f
random_noise_func	data_generator\generator.py	/^def random_noise_func():$/;"	f
random_word_color	data_generator\generator.py	/^def random_word_color():$/;"	f
random_x_y	data_generator\generator.py	/^def random_x_y(bground_size, font_size):$/;"	f
rotate_func	data_generator\generator.py	/^def rotate_func():$/;"	f
sto_choice_from_info_str	data_generator\generator.py	/^def sto_choice_from_info_str(quantity=10):$/;"	f
stretching_func	data_generator\generator.py	/^def stretching_func():$/;"	f
to_dictionary	data_generator\generator.py	/^from to_dictionary import to_dictionary$/;"	i
total	data_generator\generator.py	/^    total = 1000$/;"	v
list_a	data_generator\to_dictionary.py	/^	list_a = [3,4,5,8]$/;"	v
list_b	data_generator\to_dictionary.py	/^	list_b = [3,4,5,6,7]$/;"	v
list_c	data_generator\to_dictionary.py	/^	list_c = list(set_c)$/;"	v
set_a	data_generator\to_dictionary.py	/^	set_a = set(list_a)$/;"	v
set_b	data_generator\to_dictionary.py	/^	set_b = set(list_b)$/;"	v
set_c	data_generator\to_dictionary.py	/^	set_c = set(list_a) & set(list_b)$/;"	v
to_dictionary	data_generator\to_dictionary.py	/^def to_dictionary(text_path='', code='utf-8'):$/;"	f
Dataset	dataset.py	/^from torch.utils.data import Dataset$/;"	i
Image	dataset.py	/^from PIL import Image$/;"	i
__call__	dataset.py	/^    def __call__(self, batch):$/;"	m	class:alignCollate	file:
__call__	dataset.py	/^    def __call__(self, img):$/;"	m	class:resizeNormalize	file:
__getitem__	dataset.py	/^    def __getitem__(self, index):$/;"	m	class:lmdbDataset	file:
__init__	dataset.py	/^    def __init__(self, data_source, batch_size):$/;"	m	class:randomSequentialSampler
__init__	dataset.py	/^    def __init__(self, imgH=32, imgW=256, keep_ratio=False, min_ratio=1):$/;"	m	class:alignCollate
__init__	dataset.py	/^    def __init__(self, root=None, transform=None, target_transform=None):$/;"	m	class:lmdbDataset
__init__	dataset.py	/^    def __init__(self, size, interpolation=Image.BILINEAR):$/;"	m	class:resizeNormalize
__iter__	dataset.py	/^    def __iter__(self):$/;"	m	class:randomSequentialSampler	file:
__len__	dataset.py	/^    def __len__(self):$/;"	m	class:lmdbDataset	file:
__len__	dataset.py	/^    def __len__(self):$/;"	m	class:randomSequentialSampler	file:
alignCollate	dataset.py	/^class alignCollate(object):$/;"	c
lmdb	dataset.py	/^import lmdb$/;"	i
lmdbDataset	dataset.py	/^class lmdbDataset(Dataset):$/;"	c
np	dataset.py	/^import numpy as np$/;"	i
random	dataset.py	/^import random$/;"	i
randomSequentialSampler	dataset.py	/^class randomSequentialSampler(sampler.Sampler):$/;"	c
resizeNormalize	dataset.py	/^class resizeNormalize(object):$/;"	c
sampler	dataset.py	/^from torch.utils.data import sampler$/;"	i
six	dataset.py	/^import six$/;"	i
sys	dataset.py	/^import sys$/;"	i
torch	dataset.py	/^import torch$/;"	i
torchvision	dataset.py	/^import torchvision.transforms as transforms$/;"	i
transforms	dataset.py	/^import torchvision.transforms as transforms$/;"	i
BidirectionalLSTM	models\crnn.py	/^class BidirectionalLSTM(nn.Module):$/;"	c
CRNN	models\crnn.py	/^class CRNN(nn.Module):$/;"	c
__init__	models\crnn.py	/^    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):$/;"	m	class:CRNN
__init__	models\crnn.py	/^    def __init__(self, nIn, nHidden, nOut):$/;"	m	class:BidirectionalLSTM
convRelu	models\crnn.py	/^        def convRelu(i, batchNormalization=False):$/;"	f	function:CRNN.__init__
forward	models\crnn.py	/^    def forward(self, input):$/;"	m	class:BidirectionalLSTM
forward	models\crnn.py	/^    def forward(self, input):$/;"	m	class:CRNN
nn	models\crnn.py	/^import torch.nn as nn$/;"	i
torch	models\crnn.py	/^import torch.nn as nn$/;"	i
adadelta	params.py	/^adadelta = False$/;"	v
adam	params.py	/^adam = False$/;"	v
alphabet	params.py	/^alphabet = alphabets.alphabet$/;"	v
alphabets	params.py	/^import alphabets$/;"	i
batchSize	params.py	/^batchSize = 16$/;"	v
beta1	params.py	/^beta1 =0.5$/;"	v
crnn	params.py	/^crnn = ''$/;"	v
displayInterval	params.py	/^displayInterval = 5$/;"	v
experiment	params.py	/^experiment = '.\/expr'$/;"	v
imgH	params.py	/^imgH = 32$/;"	v
imgW	params.py	/^imgW = 160$/;"	v
keep_ratio	params.py	/^keep_ratio = False$/;"	v
lr	params.py	/^lr = 0.0001$/;"	v
n_test_disp	params.py	/^n_test_disp = 10$/;"	v
nh	params.py	/^nh = 256$/;"	v
niter	params.py	/^niter = 300$/;"	v
random_sample	params.py	/^random_sample = True$/;"	v
saveInterval	params.py	/^saveInterval = 2$/;"	v
valInterval	params.py	/^valInterval = 800$/;"	v
workers	params.py	/^workers = 2$/;"	v
char_dict	preprocessing.py	/^	char_dict = {num : char.strip().decode('gbk','ignore') for num, char in enumerate(file.readlines())}$/;"	v
value_list	preprocessing.py	/^	value_list = ['%s %s'%(segment_list.split(' ')[0], ''.join([char_dict[int(val)] for val in segment_list[:-1].split(' ')[1:]])) for segment_list in file.readlines()]$/;"	v
author	setup.py	/^    author="Jared Casper, Sean Naren",$/;"	v
author_email	setup.py	/^    author_email="jared.casper@baidu.com, sean.narenthiran@digitalreasoning.com",$/;"	v
create_extension	setup.py	/^from torch.utils.ffi import create_extension$/;"	i
description	setup.py	/^    description="PyTorch wrapper for warp-ctc",$/;"	v
enable_gpu	setup.py	/^    enable_gpu = False$/;"	v
enable_gpu	setup.py	/^    enable_gpu = True$/;"	v
ext_modules	setup.py	/^    ext_modules=[ffi],$/;"	v
extra_compile_args	setup.py	/^    extra_compile_args=extra_compile_args)$/;"	v
extra_link_args	setup.py	/^    extra_link_args=['-Wl,-rpath,' + os.path.realpath(warp_ctc_path)],$/;"	v
ffi	setup.py	/^ffi = create_extension($/;"	v
ffi	setup.py	/^ffi = ffi.distutils_extension()$/;"	v
find_packages	setup.py	/^from setuptools import setup, find_packages$/;"	i
headers	setup.py	/^    headers=headers,$/;"	v
headers	setup.py	/^headers = ['src\/cpu_binding.h']$/;"	v
include_dirs	setup.py	/^    include_dirs=include_dirs,$/;"	v
include_dirs	setup.py	/^include_dirs = [os.path.realpath('..\/include')]$/;"	v
language	setup.py	/^    language='c++',$/;"	v
lib_ext	setup.py	/^    lib_ext = ".dylib"$/;"	v
lib_ext	setup.py	/^    lib_ext = ".so"$/;"	v
libraries	setup.py	/^    libraries=['warpctc'],$/;"	v
library_dirs	setup.py	/^    library_dirs=[os.path.realpath(warp_ctc_path)],$/;"	v
license	setup.py	/^    license="Apache",$/;"	v
name	setup.py	/^    name="warpctc_pytorch",$/;"	v
name	setup.py	/^    name='warpctc_pytorch._warp_ctc',$/;"	v
os	setup.py	/^import os$/;"	i
package	setup.py	/^    package=True,$/;"	v
packages	setup.py	/^    packages=find_packages(),$/;"	v
platform	setup.py	/^import platform$/;"	i
setup	setup.py	/^from setuptools import setup, find_packages$/;"	i
sources	setup.py	/^    sources=['src\/binding.cpp'],$/;"	v
sys	setup.py	/^import sys$/;"	i
torch	setup.py	/^import torch$/;"	i
url	setup.py	/^    url="https:\/\/github.com\/baidu-research\/warp-ctc",$/;"	v
version	setup.py	/^    version="0.1",$/;"	v
warp_ctc_path	setup.py	/^    warp_ctc_path = os.environ["WARP_CTC_PATH"]$/;"	v
warp_ctc_path	setup.py	/^warp_ctc_path = "..\/build"$/;"	v
with_cuda	setup.py	/^    with_cuda=enable_gpu,$/;"	v
Image	test.py	/^from PIL import Image$/;"	i
Variable	test.py	/^from torch.autograd import Variable$/;"	i
alphabet	test.py	/^alphabet = str1$/;"	v
alphabets	test.py	/^import alphabets$/;"	i
argparse	test.py	/^import argparse$/;"	i
crnn	test.py	/^import models.crnn as crnn$/;"	i
crnn_model_path	test.py	/^crnn_model_path = 'expr\/crnn_Rec_done_9_51244.pth'$/;"	v
crnn_recognition	test.py	/^def crnn_recognition(cropped_image, model):$/;"	f
dataset	test.py	/^import dataset$/;"	i
finished	test.py	/^    finished = time.time()$/;"	v
image	test.py	/^    image = Image.open(opt.images_path)$/;"	v
model	test.py	/^        model = model.cuda()$/;"	v
model	test.py	/^    model = crnn.CRNN(32, 1, nclass, 256)$/;"	v
models	test.py	/^import models.crnn as crnn$/;"	i
nclass	test.py	/^nclass = len(alphabet)+1$/;"	v
np	test.py	/^import numpy as np$/;"	i
opt	test.py	/^opt = parser.parse_args()$/;"	v
os	test.py	/^import sys, os$/;"	i
parser	test.py	/^parser = argparse.ArgumentParser()$/;"	v
started	test.py	/^    started = time.time()$/;"	v
str1	test.py	/^str1 = alphabets.alphabet$/;"	v
sys	test.py	/^import sys, os$/;"	i
time	test.py	/^import time$/;"	i
torch	test.py	/^import torch$/;"	i
utils	test.py	/^import utils$/;"	i
Image	to_lmdb\WRImgFromLMDB.py	/^from PIL import Image$/;"	i
img	to_lmdb\WRImgFromLMDB.py	/^    img = Image.open('.\/train_images\/20456343_4045240981.jpg')$/;"	v
io	to_lmdb\WRImgFromLMDB.py	/^import io$/;"	i
lmdb	to_lmdb\WRImgFromLMDB.py	/^import lmdb$/;"	i
lmdb_path	to_lmdb\WRImgFromLMDB.py	/^    lmdb_path = '.\/lmdb'$/;"	v
np	to_lmdb\WRImgFromLMDB.py	/^import numpy as np$/;"	i
read_from_lmdb	to_lmdb\WRImgFromLMDB.py	/^def read_from_lmdb(lmdb_path,img_save_to=None):$/;"	f
a	to_lmdb\test.py	/^a=(1,)$/;"	v
data	to_lmdb\testlmdb.py	/^data  = lmdb.open(path)$/;"	v
data	to_lmdb\testlmdb.py	/^data = lmdb.open(path)$/;"	v
env_db	to_lmdb\testlmdb.py	/^env_db = lmdb.Environment('lmdb')$/;"	v
lmdb	to_lmdb\testlmdb.py	/^import  lmdb$/;"	i
os	to_lmdb\testlmdb.py	/^import os$/;"	i
path	to_lmdb\testlmdb.py	/^path = '.\/testlmdb\/'$/;"	v
txn	to_lmdb\testlmdb.py	/^txn = data.begin()$/;"	v
txn	to_lmdb\testlmdb.py	/^txn = data.begin(write=True)$/;"	v
a	to_lmdb\teststrtonum.py	/^a=list()$/;"	v
np	to_lmdb\teststrtonum.py	/^import numpy as np$/;"	i
Image	to_lmdb\tolmdb.py	/^from PIL import Image$/;"	i
by	to_lmdb\tolmdb.py	/^import lmdb # install lmdb by "pip install lmdb"$/;"	i
checkImageIsValid	to_lmdb\tolmdb.py	/^def checkImageIsValid(imageBin):$/;"	f
createDataset	to_lmdb\tolmdb.py	/^def createDataset(outputPath, imagePathList, labelList, lexiconList=None, checkValid=True):$/;"	f
cv2	to_lmdb\tolmdb.py	/^import cv2$/;"	i
imagePathList	to_lmdb\tolmdb.py	/^    imagePathList = list(imgdata)$/;"	v
imgdata	to_lmdb\tolmdb.py	/^    imgdata = open(".\/train.txt",encoding='UTF-8')$/;"	v
imghdr	to_lmdb\tolmdb.py	/^import imghdr$/;"	i
install	to_lmdb\tolmdb.py	/^import lmdb # install lmdb by "pip install lmdb"$/;"	i
labelList	to_lmdb\tolmdb.py	/^    labelList = []$/;"	v
lmdb	to_lmdb\tolmdb.py	/^import lmdb # install lmdb by "pip install lmdb"$/;"	i
np	to_lmdb\tolmdb.py	/^import numpy as np$/;"	i
os	to_lmdb\tolmdb.py	/^import os$/;"	i
outputPath	to_lmdb\tolmdb.py	/^    outputPath = ".\/lmdb"$/;"	v
re	to_lmdb\tolmdb.py	/^import re$/;"	i
word	to_lmdb\tolmdb.py	/^        word = line.split()[1]$/;"	v
writeCache	to_lmdb\tolmdb.py	/^def writeCache(env, cache):$/;"	f
checkImageIsValid	to_lmdb\tolmdb1.py	/^def checkImageIsValid(imageBin):$/;"	f
createDataset	to_lmdb\tolmdb1.py	/^def createDataset(outputPath, imagePathList, labelList, lexiconList=None, checkValid=True):$/;"	f
cv2	to_lmdb\tolmdb1.py	/^import cv2$/;"	i
glob	to_lmdb\tolmdb1.py	/^import glob$/;"	i
imagePathList	to_lmdb\tolmdb1.py	/^    imagePathList = glob.glob(path)$/;"	v
imgLabelList	to_lmdb\tolmdb1.py	/^    imgLabelList = sorted(imgLabelLists, key = lambda x:len(x[1]))$/;"	v
imgLabelLists	to_lmdb\tolmdb1.py	/^    imgLabelLists = []$/;"	v
imgPaths	to_lmdb\tolmdb1.py	/^    imgPaths = [ p[0] for p in imgLabelList]$/;"	v
install	to_lmdb\tolmdb1.py	/^import lmdb#先pip install这个模块哦$/;"	i
lmdb	to_lmdb\tolmdb1.py	/^import lmdb#先pip install这个模块哦$/;"	i
np	to_lmdb\tolmdb1.py	/^import numpy as np$/;"	i
os	to_lmdb\tolmdb1.py	/^import os$/;"	i
outputPath	to_lmdb\tolmdb1.py	/^    outputPath = 'D:\/ruanjianxiazai\/tuxiangyangben\/fengehou\/train'#训练集和验证集要跑两遍这个程序，分两次生成$/;"	v
path	to_lmdb\tolmdb1.py	/^    path = "D:\/ruanjianxiazai\/tuxiangyangben\/fengehou\/chenguang\/*.jpg"#将txt与jpg的都放在同一个文件里面$/;"	v
pip	to_lmdb\tolmdb1.py	/^import lmdb#先pip install这个模块哦$/;"	i
read_text	to_lmdb\tolmdb1.py	/^def read_text(path):$/;"	f
txtLists	to_lmdb\tolmdb1.py	/^    txtLists = [ p[1] for p in imgLabelList]$/;"	v
writeCache	to_lmdb\tolmdb1.py	/^def writeCache(env, cache):$/;"	f
Variable	utils.py	/^from torch.autograd import Variable$/;"	i
__init__	utils.py	/^    def __init__(self):$/;"	m	class:averager
__init__	utils.py	/^    def __init__(self, alphabet, ignore_case=False):$/;"	m	class:strLabelConverter
add	utils.py	/^    def add(self, v):$/;"	m	class:averager
assureRatio	utils.py	/^def assureRatio(img):$/;"	f
averager	utils.py	/^class averager(object):$/;"	c
collections	utils.py	/^import collections$/;"	i
decode	utils.py	/^    def decode(self, t, length, raw=False):$/;"	m	class:strLabelConverter
encode	utils.py	/^    def encode(self, text):$/;"	m	class:strLabelConverter
loadData	utils.py	/^def loadData(v, data):$/;"	f
nn	utils.py	/^import torch.nn as nn$/;"	i
oneHot	utils.py	/^def oneHot(v, v_length, nc):$/;"	f
prettyPrint	utils.py	/^def prettyPrint(v):$/;"	f
reset	utils.py	/^    def reset(self):$/;"	m	class:averager
strLabelConverter	utils.py	/^class strLabelConverter(object):$/;"	c
torch	utils.py	/^import torch$/;"	i
torch	utils.py	/^import torch.nn as nn$/;"	i
val	utils.py	/^    def val(self):$/;"	m	class:averager
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_PROGRAM_VERSION	5.8	//
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
